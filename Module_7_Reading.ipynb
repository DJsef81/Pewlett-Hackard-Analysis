{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES FOR MODULE 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1.1 Tools for SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL\n",
    "\n",
    "# typically referred to as just \"Postgres,\" is a relational database system. \n",
    "\n",
    "# This type of database consists of tables and their predefined relationships.\n",
    "# \"Relationships\" are how each table relates to another. \n",
    "\n",
    "# Another aspect of Postgres is that it will create a local server on your computer, which is where the databases we \n",
    "# create will be stored. Then the databases will store the tables and the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgAdmin \n",
    "\n",
    "# is the window into our database: it's where queries are written and executed and where results are viewed. \n",
    "\n",
    "# While Postgres holds the files, pgAdmin provides the access. All SQL actions take place within these two programs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2.2 Create Tables in SQL\n",
    "\n",
    "# Use our final ERD as a guide\n",
    "\n",
    "# create six tables, one for each CSV file\n",
    "\n",
    "# These table creation statements will be our first introduction to Structured Query Language. \n",
    "\n",
    "# A statement is a block of code that, when executed, sends a command to the database.\n",
    "\n",
    "#  Before we create database, review Diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Diagrams\n",
    "\n",
    "# recreating the same tables in the diagram in our SQL database.\n",
    "\n",
    "# With the help of the diagram, we know the structure of this table: two columns with their data types. \n",
    "# Also, the table is already named. All we need to do is transfer over the same information.\n",
    "\n",
    "# Start by using..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Query Tool is pgAdmin's text editor, much like VSCode is for Python.\n",
    "\n",
    "# so lets create a table\n",
    "\n",
    "# -- Creating tables for PH-EmployeeDB\n",
    "# CREATE TABLE departments (\n",
    "#      dept_no VARCHAR(4) NOT NULL,\n",
    "#     dept_name VARCHAR(40) NOT NULL,\n",
    "#     PRIMARY KEY (dept_no),\n",
    "#     UNIQUE (dept_name)\n",
    "#);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE is the syntax required to create a new table in SQL.\n",
    "\n",
    "# departments is the name of the table and how it will be referenced in queries.\n",
    "\n",
    "# So the table has been named, now the structure needs to be created. The content inside the parentheses is how we'll \n",
    "# do that.\n",
    "\n",
    "# dept_no VARCHAR(4) NOT NULL, creates a column named \"dept_no\" that can hold up to four varying characters, while \n",
    "# NOT NULL tells SQL that no null fields will be allowed when importing data.\n",
    "\n",
    "# There are times when we don't want a data field to be null. For example, the dept_no column is our primary key—each \n",
    "# row has a unique number associated with it. If we didn't have the NOT NULL constraint, then there's a chance that a \n",
    "# row (or more than one row) won't have a primary key associated with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think would happen if one of the rows didn’t have a unique identifier?\n",
    "\n",
    "# Not all of the data would be present in every query, which would skew analysis results and provide incomplete lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dept_name VARCHAR(40) NOT NULL, creates a column similar to the dept_no, only the varying character count has a \n",
    "# maximum of 40.\n",
    "\n",
    "# PRIMARY KEY (dept_no), means that the dept_no column is used as the primary key for this table.\n",
    "\n",
    "# UNIQUE (dept_name) adds the unique constraint to the dept_name column.\n",
    "\n",
    "# The unique constraint implies that the data in that column is unique. \n",
    "# This ensures that if the table were to be updated in the future, nothing will be duplicated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The closing parenthesis and semicolon signal that the SQL CREATE TABLE statement is complete. \n",
    "\n",
    "# Any code added after will need to be included in a new SQL statement. \n",
    "# A statement is a command that is set up with a certain syntax. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does it mean when the NOT NULL constraint is applied?\n",
    "\n",
    "# Null values are not allowed in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Code\n",
    "\n",
    "# To save the table to the database, we need to execute the code. \n",
    "\n",
    "# In the toolbar of the pgAdmin webpage, find and click the lightning bolt symbol toward the right of the bar. \n",
    "\n",
    "# This button runs the code and saves our work to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshoot Error Messages\n",
    "\n",
    "# Any error message will also appear in the same manner. Encountering errors will happen often and troubleshooting \n",
    "# them is a large part of being a developer. \n",
    "\n",
    "# Thankfully, each error message encountered will tell us why the error occurred. \n",
    "# This is great because it helps us, the developers, research and fix the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR:  relation \"departments\" already exists\n",
    "# SQL state: 42P07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This error occurs because SQL data is persistent and cannot be overwritten if the same command is run again. \n",
    "# Once a table has been committed to a database, it is there until a different command is run to delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data integrity is the quality of the data we're working with. Clean data will yield better results in analysis, \n",
    "# and maintaining the data integrity ensures greater accuracy and reliability.\n",
    "\n",
    "# Dirty data is data that contains errors such as duplicates, undefined values (i.e., not a number, or NaN), or other \n",
    "# inconsistencies. This is why the NOT NULL constraint is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid encountering this error, highlight the code block you want to run first, then execute it. \n",
    "# This tells pgAdmin to run only that code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Additional Tables\n",
    "\n",
    "# Create another table for Employees.\n",
    "\n",
    "# How to start create table: \n",
    "\n",
    "# CREATE TABLE employees (\n",
    "#     emp_no INT NOT NULL,\n",
    "#     birth_date DATE NOT NULL,\n",
    "#     first_name VARCHAR NOT NULL,\n",
    "#     last_name VARCHAR NOT NULL,\n",
    "#     gender VARCHAR NOT NULL,\n",
    "#     hire_date DATE NOT NULL,\n",
    "#     PRIMARY KEY (emp_no)\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one more together—this time with foreign keys included. \n",
    "# Add the following code to the bottom of your query editor:\n",
    "\n",
    "# CREATE TABLE dept_manager (\n",
    "# dept_no VARCHAR(4) NOT NULL,\n",
    "#     emp_no INT NOT NULL,\n",
    "#     from_date DATE NOT NULL,\n",
    "#     to_date DATE NOT NULL,\n",
    "# FOREIGN KEY (emp_no) REFERENCES employees (emp_no),\n",
    "# FOREIGN KEY (dept_no) REFERENCES departments (dept_no),\n",
    "#     PRIMARY KEY (emp_no, dept_no)\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that foreign keys reference the primary key of other tables. In the two lines above we can see that:\n",
    "\n",
    "# The FOREIGN KEY constraint tells Postgres that there is a link between two tables\n",
    "\n",
    "# The parentheses following FOREIGN KEY specify which of the current table's columns is linked to another table\n",
    "\n",
    "# REFERENCES table_name (column_name) tells Postgres which other table uses that column as a primary key\n",
    "\n",
    "# The primary key is similar, but there are two keys listed this time instead of just one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One thing to keep in mind when working with foreign keys is that it's possible that data insertion will fail if the\n",
    "# foreign key isn't present. \n",
    "\n",
    "# This is a \"foreign key constraint\" and in this case, it means that the new data needs a reference point \n",
    "# (such as dept_no or emp_no) to be successfully added to the table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create another table for the data in salaries.csv\n",
    "\n",
    "# CREATE TABLE salaries (\n",
    "#   emp_no INT NOT NULL,\n",
    "#   salary INT NOT NULL,\n",
    "#   from_date DATE NOT NULL,\n",
    "#   to_date DATE NOT NULL,\n",
    "#   FOREIGN KEY (emp_no) REFERENCES employees (emp_no),\n",
    "#   PRIMARY KEY (emp_no)\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code tells Postgres that our new table is named \"salaries\" and we'll have columns for the emp_no, salary, \n",
    "#from_date, and to_date. \n",
    "\n",
    "# We also have specified that certain fields aren't allowed any null space with the NOT NULL constraint, which is \n",
    "# important because we want this data to be persistent for every employee. \n",
    "\n",
    "# As a final step in table creation, we've also specified primary and foreign keys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for Confirmation\n",
    "\n",
    "# Confirm the tables were created successfully by running a SELECT statement, which performs a query instead of \n",
    "# constructing anything.\n",
    "\n",
    "# Think of it as asking the database a question. For example, say we want to know how many columns are in the \n",
    "# departments table. \n",
    "# How would we ask that particular question? We would create a SELECT statement, then run the code. \n",
    "# This is called \"querying the database.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to query how many columns ar in the departments table\n",
    "\n",
    "# In the editor, after the table creation statements, type \n",
    "\n",
    "# SELECT * FROM departments;\n",
    "\n",
    "# The SELECT statement tells Postgres that we're about to query the database.\n",
    "# The asterisk tells Postgres that we're looking for every column in a table.\n",
    "# FROM departments tells pgAdmin which table to search.\n",
    "# The semicolon signifies the completion of the query.\n",
    "# After executing the SELECT statement, pgAdmin will automatically show the result in the Data Output tab at the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The information in the database is static, which means that it will always be in the database unless directly \n",
    "# altered, but the query editor is not. \n",
    "\n",
    "# It's similar to working in a Microsoft Word document: If something happens to your computer before you saved your \n",
    "# work, there's a good chance it'll be lost. \n",
    "\n",
    "# If your computer crashes mid-query, the pgAdmin editor won't hold onto your code for you during a reboot.\n",
    "\n",
    "# Our queries are the meat and potatoes of SQL. We're finding connections between different tables and answering \n",
    "# questions with the results. \n",
    "\n",
    "# Even though losing a query isn't the end of the world (they can be rebuilt, after all), it does take time to \n",
    "# replicate the work already completed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2.3 Import Data\n",
    "\n",
    "# we've created a database. We've written our first SQL code and created tables modeled after our ERD. \n",
    "\n",
    "# The next step is to import the data from the CSV files. \n",
    "\n",
    "# We'll make sure all of the tables we created in pgAdmin appear in the GUI first, because we'll be using the GUI to \n",
    "# import data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL is very interactive. Developers are not only importing data and asking it questions through the query language, \n",
    "# but they can also update and edit the data stored in the tables as needed.\n",
    "\n",
    "# For example, if a single row of data needs to be added to an existing table, a developer can manually add it by \n",
    "# using the INSERT statement.\n",
    "\n",
    "# If the data in a table is small enough in scale, it can be manually inserted this way completely, instead of \n",
    "# importing a CSV file.\n",
    "\n",
    "# Alternately, necessary edits and updates are completed manually as well. \n",
    "\n",
    "# We won't be manually editing or uploading data to our tables in this lesson because our datasets are too large.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep to import csv files into PH-EmployeeDB\n",
    "\n",
    "# In the pgAdmin window, select the dropdown menu for our PH-EmployeeDB database. To import data into the tables, first confirm all of our tables are listed:\n",
    "\n",
    "# Find the PH-EmployeeDB collapsible menu and click it.\n",
    "# Scroll down and click \"Schemas\" to expand the menu.\n",
    "# Click \"public.\"\n",
    "# Scroll down to \"Tables\" and note the number in parentheses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Import \n",
    "\n",
    "# To import a CSV into Postgres with pgAdmin, follow these steps. We'll customize our options to fit our data import, \n",
    "# and then check the table to make sure the data has been imported successfully. \n",
    "\n",
    "# Right-click the first table, departments.\n",
    "\n",
    "# From the menu that pops up, scroll to Import/Export. \n",
    "\n",
    "# Toggle the button to show \"Import.\" \n",
    "\n",
    "# Click the ellipsis on the Filename field to search for your project folder.\n",
    "\n",
    "# Select departments.csv. Make sure Format is set to \"csv\" and Encoding is blank. Note: By default, the Encoding \n",
    "# section is blank. \n",
    "# If our files were encoded to provide an extra layer of security, we would need to select the type of encoding before\n",
    "# importing them to Postgres. \n",
    "# We don't have to worry about this, though. \n",
    "# Also, if \"Encoding\" is filled in with an encoding type such as BIG5 or LATIN1, cancel the import and start over. \n",
    "\n",
    "# Leave the OID field as is, but toggle the Header field to \"Yes\" and select the comma as the Delimiter. \n",
    "# Note: If we don't specify that there is already a header included in the CSV data, then the header will be imported \n",
    "# as data. This would result in errors because headers don't always match the data types in the columns. \n",
    "\n",
    "# Click OK to begin importing the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the import by typing SELECT * FROM departments; at the bottom of the query editor. \n",
    "# The resulting table should mirror the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2.4 Troubleshoot Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Common Errors\n",
    "\n",
    "# What if Bobby runs into an error while he's importing the data? Below is an example of a likely error:\n",
    "\n",
    "# DETAIL: Key(Emp_no)=10001 is not present in table \"employees\"\n",
    "\n",
    "# Because the FOREIGN KEY constraint references other tables, we need to import the data in a specific order.\n",
    "\n",
    "# For example, the dept_emp table references the Employees table through its foreign key. \n",
    "# If there is no data in the Employees table, then there are no foreign keys to link to, and an error will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Mismatched Data Types\n",
    "\n",
    "# Another common scenario is when a data type in a table we've created doesn't match the CSV data. What should we do?\n",
    "\n",
    "# Because data within a Postgres database is static, we can't go back and fix a typo in our original table creation \n",
    "# code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to update a table column to fix its data type, what is the best approach?\n",
    "# Delete the table, then recreate it after updating the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a Table\n",
    "\n",
    "# To drop the table, the following code is used:\n",
    "\n",
    "# DROP TABLE employees CASCADE;\n",
    "\n",
    "# DROP TABLE employees tells Postgres that we want to remove the Employees table from the database completely.\n",
    "# CASCADE; indicates that we also want to remove the connections to other tables in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More on CASCADE\n",
    "\n",
    "# Even without data, by adding foreign keys that reference other tables, we've created a network of data connections. \n",
    "\n",
    "# Not every table will need the CASCADE constraint, but it will come up when you need to drop a table that already has \n",
    "# a defined relationship with another. \n",
    "\n",
    "# Any table that does not reference a foreign key can be dropped without the CASCADE constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3.1 Query Dates\n",
    "\n",
    "# future-proofing the company by determining how many people will be retiring and, of those employees, who is eligible \n",
    "# for a retirement package.\n",
    "\n",
    "# In Python, conditionals such as \"if\" and \"else,\" and the logical operator \"and,\" are similar to conditional \n",
    "# expressions used in SQL\n",
    "\n",
    "# search for folks who are retiring soon. The query he builds will include a condition involving employee birthdays. \n",
    "# We need to know when they were born to determine when they'll retire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Retirement Eligibility\n",
    "\n",
    "# anyone born between 1952 and 1955 will begin to retire. \n",
    "\n",
    "# The first query we need to help Bobby write will return a list of those employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT first_name, last_name\n",
    "# FROM employees\n",
    "# WHERE birth_date BETWEEN '1952-01-01' AND '1955-12-31';\n",
    "\n",
    "\n",
    "# The SELECT statement is more specific this time. Instead of an asterisk to indicate that we want all of the records,\n",
    "# we're requesting only the first and last names of the employees.\n",
    "\n",
    "# FROM employees tells SQL in which of the six tables to look.\n",
    "\n",
    "# The WHERE clause brings up even more specifics. We want SQL to look in the birth_date column for anyone born between\n",
    "# January 1, 1952, and December 31, 1955.\n",
    "\n",
    "# Notice how BETWEEN and AND are both capitalized in our statement? This is part of the SQL syntax. \n",
    "# It not only signals the conditions present, but also makes the code easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many employees are ready for retirement?\n",
    "\n",
    "# 10,000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pewlett Hackard has a lot of employees getting ready to age out of the program. \n",
    "# This is going to create a considerable amount of openings. Refine this list further by looking only at how many \n",
    "# employees were born in 1952. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another query that will search for only 1952 birth dates.\n",
    "\n",
    "# SELECT first_name, last_name\n",
    "# FROM employees\n",
    "# WHERE birth_date BETWEEN '1952-01-01' AND '1952-12-31';\n",
    "\n",
    "# This query is almost the same as the last. We've only changed a single digit: the year was switched from 1955 to \n",
    "# 1952 after the AND clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow the Search for Retirement Eligibility\n",
    "\n",
    "# There are quite a few folks getting ready to retire. Each of those new queries has a lengthy list of people. \n",
    "\n",
    "# Let's see if we can narrow it down a bit more by adding another condition to the query. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified query \n",
    "\n",
    "# -- Retirement eligibility\n",
    "# SELECT first_name, last_name\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We modified this query to include a specific hiring range. This time, we're looking for employees born between 1952 \n",
    "# and 1955, who were also hired between 1985 and 1988. \n",
    "\n",
    "# The modification is subtle, too. We're going to adjust one line of the code block and add another to the end.\n",
    "\n",
    "# The first piece, an adjustment, is to place parentheses around the WHERE clause (without including the keyword \n",
    "# itself). We'll also remove the semicolon since the code block isn't complete yet. \n",
    "\n",
    "# dd the final line of code. Our current code has a single condition in place that tells Postgres to search only for \n",
    "# people born between 1952 and 1955. The next line of code is our second condition that they were also hired between \n",
    "# 1985 and 1988.\n",
    "\n",
    "# the second condition is inside parentheses? This is a tuple; in Python, data can be stored inside a tuple and \n",
    "# accessed in the same way as a list. \n",
    "\n",
    "# In SQL, the tuples in this block of code are part of the syntax. They basically place each condition in a group, \n",
    "# and Postgres looks for the first group first, then looks inside the second group to deliver the second condition.\n",
    "\n",
    "# The SELECT statement, pulling data from the first and last name columns\n",
    "# The FROM statement, telling Postgres from which table we're getting the data\n",
    "# And two conditional statements: the dates of birth and the dates of hire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Queries\n",
    "\n",
    "# -- Number of employees retiring\n",
    "# SELECT COUNT(first_name)\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Tables\n",
    "\n",
    "# This time, the change we'll make to the code is also small—we're modifying the SELECT statement into a SELECT INTO \n",
    "# statement. \n",
    "# This statement tells Postgres that instead of generating a list of results, the data is saved as a new table \n",
    "# completely. \n",
    "\n",
    "# Update our code to include the INTO portion of the SELECT statement.\n",
    "\n",
    "# Insert a new, blank line between the SELECT and FROM sections of the code. \n",
    "# In this vacant space, type in INTO retirement_info. With the addition of this line, we're telling Postgres to save \n",
    "# the data into a table named \"retirement_info.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- create a new table of retiring employees\n",
    "\n",
    "# SELECT first_name, last_name\n",
    "# INTO retirement_info\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our list of data from earlier is now an actual table that we can use with statements and functions to perform \n",
    "# analysis. \n",
    "\n",
    "# Additionally, if you refresh the list of tables from the dropdown menu on the left, it will now appear in the list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "\n",
    "# Right-click on your new table and select \"Import/Export.\" \n",
    "# Instead of importing anything, this time we'll be exporting.\n",
    "\n",
    "# STEPS\n",
    "\n",
    "# Keep the Import/Export button toggled to \"Export.\"\n",
    "\n",
    "# Click on the ... in the Filename field to automatically select the same directory from which you imported the other \n",
    "# CSVs. Select a directory, but be sure to rename it to retirement_info.csv.\n",
    "\n",
    "# Be sure the format is still CSV.\n",
    "\n",
    "# Toggle the Header section to \"Yes\" to include column names in the new CSV files.\n",
    "\n",
    "# Select the comma as the delimiter to maintain the same format with all CSV files.\n",
    "\n",
    "# Click OK to start the export. After the file has been created, pgAdmin will confirm our file is ready to be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3.2 Join the Tables\n",
    "\n",
    "# Our queries have helped Bobby complete the task that was asked of him, but the number of retirement-ready employees\n",
    "# was staggering.\n",
    "\n",
    "# Bobby's been asked to dive back into SQL and create a separate list of employees for each department. \n",
    "\n",
    "# We can only gain so much information from our data as it stands, so we'll need to start combining it in different \n",
    "# ways using joins.\n",
    "\n",
    "# Merging DataFrames in Pandas is very similar to joining tables in SQL. There are several different types of joins \n",
    "# and each one will yield a different result. \n",
    "\n",
    "# We'll cover each type of join available in SQL as well as where and when to use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sense of Tables with Joins\n",
    "\n",
    "# Right now, there are seven tables available for us to use. Between them, we have all of the information we need to \n",
    "# help Bobby create his new lists, but the data is in separate tables. \n",
    "\n",
    "# We could present multiple lists and explain the connections, but that's messy and confusing. \n",
    "\n",
    "# Instead, we need to perform a join on the different tables. In SQL, combining two or more tables is called a join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much like joining Python DataFrames, we can join SQL tables together using a common column. \n",
    "# We don't have to join complete tables. We can specify which columns from each table we'd like to see joined. \n",
    "# Take another look at our ERD.\n",
    "\n",
    "# Bobby's boss wants the same list of employees—only he wants them broken down into departments. We can already see \n",
    "# that the Employees and Departments tables don't have a common column between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which tables would you join together to help Bobby create a list of employees grouped by their departments?\n",
    "\n",
    "# Join the Employees table to the Dept_Emp table on the emp_no column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dept_Emp table contains both an emp_no and a dept_no. Between the Employees table and the Dept_Emp table, we would have:\n",
    "\n",
    "# Employee numbers\n",
    "# Employee names\n",
    "# Their departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could combine the two tables to have everything we need for Bobby's boss. Except, the Employees table still \n",
    "# contains every employee, not just those getting ready for retirement. \n",
    "\n",
    "# Our retirement_info table has the correct list of employees, but not their employee number, so we can't actually \n",
    "# join it with anything.\n",
    "\n",
    "# What we'll need to help Bobby do first is recreate the retirement_info table so it includes the emp_no column. \n",
    "\n",
    "# With this column in place, we'll be able to join our new table full of future retirees to the Dept_Emp table, so we \n",
    "# know which departments will have job openings (and how many).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the code for dropping a table?\n",
    "# DROP TABLE retirement_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the retirement_info Table with the emp_no Column\n",
    "\n",
    "# The first task we'll help Bobby with is recreating the retirement_info table so it contains unique identifiers \n",
    "# (the emp_no column). This way, we will be able to perform joins using this table and others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the current retirement_info table. At the bottom of the query editor, type DROP TABLE retirement_info; and then\n",
    "# execute the code. \n",
    "\n",
    "# Next, we're going to update our code to create the retirement_info table. \n",
    "\n",
    "# Keeping the ERD in mind, we know we want the unique identifier column included in our new table. \n",
    "\n",
    "# Add that to our select statement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Create new table for retiring employees\n",
    "# SELECT emp_no, first_name, last_name\n",
    "# INTO retirement_info\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');\n",
    "# -- Check the table\n",
    "# SELECT * FROM retirement_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See \"Types_of_joins\" file for joins info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Aliases for Code Readability\n",
    "\n",
    "# Joining tables can get messy. There are several different table and column name combinations to keep track of, and \n",
    "# they can get lengthy as the query is created.\n",
    "\n",
    "# SQL has a method to shorten the code and provide greater readability by using an alias instead of a full tablename.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alias in SQL allows developers to give nicknames to tables. This helps improve code readability by shortening \n",
    "# longer names into one-, two-, or three-letter temporary names. \n",
    "# This is commonly used in joins because multiple tables and columns are often listed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparisons of previous code vs. aliases code \n",
    "\n",
    "# -- Joining retirement_info and dept_emp tables (Left Join)\n",
    "# SELECT retirement_info.emp_no,\n",
    "#      retirement_info.first_name,\n",
    "#  retirement_info.last_name,\n",
    "#      department_employees.to_date    \n",
    "#  FROM retirement_info\n",
    "#  LEFT JOIN department_employees\n",
    "#  ON retirement_info.emp_no = department_employees.emp_no;\n",
    "\n",
    "# -- Using Aliases instead of full table titles, refactoring \"joining retirement_info and Department_Employees with left join\"\n",
    "#  SELECT ri.emp_no,\n",
    "#     ri.first_name,\n",
    "# ri.last_name,\n",
    "#     de.to_date\n",
    "# FROM retirement_info as ri\n",
    "# LEFT JOIN dept_emp as de\n",
    "# ON ri.emp_no = de.emp_no;\n",
    "\n",
    "# -- Joining departments and dept_manager tables\n",
    "# SELECT departments.dept_name,\n",
    "#      dept_manager.emp_no,\n",
    "#      dept_manager.from_date,\n",
    "#      dept_manager.to_date\n",
    "# FROM departments\n",
    "# INNER JOIN dept_manager\n",
    "# ON departments.dept_no = dept_manager.dept_no;\n",
    "\n",
    "# -- Refactoring Joining departments and dept_manager tables with aliases\n",
    "# SELECT d.dept_name,\n",
    "#      dm.emp_no,\n",
    "#      dm.from_date,\n",
    "#      dm.to_date\n",
    "# FROM departments as d\n",
    "# INNER JOIN dept_manager as dm\n",
    "# ON d.dept_no = dm.dept_no;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Left Join for retirement_info and dept_emp tables\n",
    "\n",
    "# Now that we have a list of all retirement-eligible employees, it's important to make sure that they are actually \n",
    "# still employed with PH. \n",
    "\n",
    "# To do so, we're going to perform another join, this time between the retirement_info and dept_emp tables. \n",
    "\n",
    "# The basic information to include in the new list is:\n",
    "\n",
    "# Employee number\n",
    "# First name\n",
    "# Last name\n",
    "# To-date\n",
    "\n",
    "# In the pgAdmin query editor, let's begin by specifying these columns and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the pgAdmin query editor, let's begin by specifying these columns and tables.\n",
    "\n",
    "# SELECT ri.emp_no,\n",
    "#     ri.first_name,\n",
    "#     ri.last_name,\n",
    "# de.to_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to create a new table to hold the information. Let's name it \"current_emp.\"\n",
    "\n",
    "# INTO current_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to add the code that will join these two tables.\n",
    "\n",
    "# FROM retirement_info as ri\n",
    "# LEFT JOIN dept_emp as de\n",
    "# ON ri.emp_no = de.emp_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, because this is a table of current employees, we need to add a filter, using the WHERE keyword and the \n",
    "# date 9999-01-01.\n",
    "\n",
    "# WHERE de.to_date = ('9999-01-01');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3.4 Use Count, Group By, and Order By\n",
    "\n",
    "# We know that we'll need to use some joins to organize the data we need in one table. \n",
    "\n",
    "# We also know that Bobby needs a count of employees for each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To organize the counts, we'll need to add a GROUP BY clause to our select statement. \n",
    "\n",
    "# In Postgres, GROUP BY is used when we want to group rows of identical data together in a table. \n",
    "\n",
    "# It is precisely the clause we want to group separate employees into their departments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your query editor, join the current_emp and dept_emp tables. The new code should be added at the bottom, below \n",
    "# the existing code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Employee count by department number\n",
    "# SELECT COUNT(ce.emp_no), de.dept_no\n",
    "# FROM current_emp as ce\n",
    "# LEFT JOIN dept_emp as de\n",
    "# ON ce.emp_no = de.emp_no\n",
    "# GROUP BY de.dept_no;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few things to note:\n",
    "\n",
    "# The COUNT function was used on the employee numbers.\n",
    "\n",
    "# Aliases were assigned to both tables.\n",
    "\n",
    "# GROUP BY was added to the SELECT statement.\n",
    "\n",
    "# We added COUNT() to the SELECT statement because we wanted a total number of employees. \n",
    "# We couldn't actually use the SUM() function because the employee numbers would simply be added, which would leave \n",
    "# us with one really large and useless number.\n",
    "\n",
    "# Bobby's boss asked for a list of how many employees per department were leaving, so the only columns we really \n",
    "# needed for this list were the employee number and the department number.\n",
    "\n",
    "# We used a LEFT JOIN in this query because we wanted all employee numbers from Table 1 to be included in the returned\n",
    "# data. Also, if any employee numbers weren't assigned a department number, that would be made apparent.\n",
    "\n",
    "# The ON portion of the query tells Postgres which columns we're using to match the data. Both tables have an \n",
    "# emp_no column, so we're using that to match the records from both tables.\n",
    "\n",
    "# GROUP BY is the magic clause that gives us the number of employees retiring from each department.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did you notice that the data output isn't in any particular order? In fact, if you executed the code again, the same\n",
    "# numbers would be returned in another order altogether. \n",
    "\n",
    "# Thankfully, there is one additional clause we can add to the query to keep everything in order: ORDER BY.\n",
    "\n",
    "# ORDER BY does exactly as it reads: It puts the data output in order for us. \n",
    "\n",
    "# Let's update our code. In the query editor, add the ORDER BY line to the end of the code block, so your code looks \n",
    "# like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Employee count by department number\n",
    "# SELECT COUNT(ce.emp_no), de.dept_no\n",
    "# FROM current_emp as ce\n",
    "# LEFT JOIN dept_emp as de\n",
    "# ON ce.emp_no = de.emp_no\n",
    "# GROUP BY de.dept_no\n",
    "# ORDER BY de.dept_no;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3.5 Create Additional Lists\n",
    "\n",
    "# Because of the number of people leaving each department, the boss has requested three lists that are more specific:\n",
    "\n",
    "# 1. Employee Information: A list of employees containing their unique employee number, their last name, first name, \n",
    "# gender, and salary\n",
    "\n",
    "# 2. Management: A list of managers for each department, including the department number, name, and the manager's \n",
    "# employee number, last name, first name, and the starting and ending employment dates\n",
    "\n",
    "# 3. Department Retirees: An updated current_emp list that includes everything it currently has, but also the \n",
    "# employee's departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 1: Employee Information\n",
    "\n",
    "# The first requested list is general employee information, but with their current salaries included. \n",
    "\n",
    "# in our ERD, Employees table and salaries table are connected by emp_no\n",
    "\n",
    "# he only problem is that the Employees table holds data for all employees, even the ones who are not retiring. \n",
    "# If we use this table, we will have a far bigger list to present than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To include all of the information Bobby's manager wants, we'll need to create an entirely new table from the \n",
    "# beginning. Here's everything we need:\n",
    "\n",
    "# Employee number\n",
    "# First name\n",
    "# Last name\n",
    "# Gender\n",
    "# to_date\n",
    "# Salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to our ERD, the Salaries table has a to_date column in it. \n",
    "\n",
    "# Let's make sure it aligns with the employment date or something else. \n",
    "\n",
    "# Run a SELECT statement in the query editor to take a look.\n",
    "\n",
    "# SELECT * FROM salaries;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dates are all over the place. We want to know what the most recent date on this list is, so let's sort that \n",
    "# column in descending order. \n",
    "\n",
    "# Back in the query editor, modify our select statement as follows:\n",
    "\n",
    "# SELECT * FROM salaries\n",
    "# ORDER BY to_date DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks a little better, but what's wrong with the date? It's certainly not the most recent date of employment, \n",
    "# so it must have something to do with salaries. \n",
    "\n",
    "# Looks like we'll need to pull employment dates from the dept_emp table again.\n",
    "\n",
    "# Now that we know what data we need from which tables, we can get started. \n",
    "\n",
    "# It doesn't have to be from scratch, though. We've already created code to filter the Employees table to show only\n",
    "# employes born and hired at the correct time, so let's look at our query editor to see if we can reuse that code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous code we will refractor \n",
    "\n",
    "# -- Create a new table of retiring employees\n",
    "# SELECT first_name, last_name\n",
    "# INTO retirement_info\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gender\n",
    "\n",
    "# SELECT emp_no,\n",
    "#     first_name,\n",
    "# last_name,\n",
    "#     gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't want to save this query into the same table we used before. Not only would it be confusing, but Postgres \n",
    "# wouldn't allow it anyway. \n",
    "\n",
    "# We'll want to update the INTO portion. \n",
    "\n",
    "# The rest of the code looks good, as we want the same filters to be in place, so leave it as-is.\n",
    "\n",
    "# INTO emp_info\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new refractored code \n",
    "\n",
    "# -- Create a new table of retiring employees refractored (add gender, create new temporary table)\n",
    "# SELECT emp_no,\n",
    "#     first_name,\n",
    "# last_name,\n",
    "#     gender\n",
    "#     INTO emp_info\n",
    "# FROM employees\n",
    "# WHERE (birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "# AND (hire_date BETWEEN '1985-01-01' AND '1988-12-31');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our employees table has been filtered again and is being saved into a new temporary table (emp_info), we \n",
    "# need to join it to the salaries table to add the to_date and Salary columns to our query. \n",
    "\n",
    "# This will require a join, so let's get started. \n",
    "\n",
    "# First, update the SELECT statement by adding the two columns we need from the Salaries table. \n",
    "\n",
    "# Remember to use aliases to make it easier to read.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns are accounted for.\n",
    "\n",
    "# SELECT e.emp_no,\n",
    "#    e.first_name,\n",
    "# e.last_name,\n",
    "#     e.gender,\n",
    "#     s.salary,\n",
    "#     de.to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already know we're naming our new table emp_info, so we can leave the INTO statement as-is. \n",
    "\n",
    "# Let's move on to the joins. In this case, we'll use inner joins in our query. \n",
    "\n",
    "# This is because we want only the matching records.\n",
    "\n",
    "# Back in the query editor, update the INTO and FROM lines, then add the first join directly below.\n",
    "\n",
    "# INTO emp_info\n",
    "# FROM employees as e\n",
    "# INNER JOIN salaries as s\n",
    "# ON (e.emp_no = s.emp_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to this point, we have updated and added code to:\n",
    "\n",
    "# Select columns from three tables\n",
    "# Create a new temp table\n",
    "# Add aliases\n",
    "# Join two of the three tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third join seems tricky, but thankfully, the syntax is exactly the same. \n",
    "# All we need to do is add the next join right under the first. Back in the query editor, add the following:\n",
    "\n",
    "# INNER JOIN dept_emp as de\n",
    "# ON (e.emp_no = de.emp_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost there! We have all of the joins, but we still need to make sure the filters are in place correctly. \n",
    "\n",
    "# The birth and hire dates are still resting right under our joins, so update that with the proper aliases. \n",
    "\n",
    "# For more on how to join two or more tables, refer to Joining More than Two Tables (Links to an external site.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHERE (e.birth_date BETWEEN '1952-01-01' AND '1955-12-31')\n",
    "#      AND (e.hire_date BETWEEN '1985-01-01' AND '1988-12-31')\n",
    "\n",
    "# Okay, now we have joined all three tables and have updated the birth and hire date filters to reference the correct \n",
    "# table using an alias. We have one more filter to add, then we're ready to check and export the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last filter we need is the to_date of 999-01-01 from the dept_emp table. \n",
    "\n",
    "# To add another filter to our current WHERE clause, we will use AND again. In the query editor, add this last line:\n",
    "\n",
    "#      AND (de.to_date = '9999-01-01');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we create a temporary table using this code, comment out the INTO line so that we don't run it with the rest.\n",
    "\n",
    "# This way, we'll be able to see the results of our code immediately. \n",
    "\n",
    "# This is useful because if there is a mistake, we won't need to backtrack and delete the table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the INTO emp_info line and press Command + forward slash, / (for Mac)\n",
    "\n",
    "# This will automatically add the double hyphen to indicate a comment. \n",
    "\n",
    "# Now highlight the entire block and run the code.\n",
    "\n",
    "# The results are looking good and the list contains everything Bobby's boss requested. \n",
    "\n",
    "# Let's uncomment INTO and run the code again to save the temporary table. \n",
    "\n",
    "# Remember to export this list as a CSV into your current project folder.\n",
    "\n",
    "# Those salaries still look a little strange, though. \n",
    "\n",
    "# Bobby will need to ask his manager about the lack of employee raises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 2: Management\n",
    "\n",
    "# The next list to work on involves the management side of the business. \n",
    "# Many employees retiring are part of the management team, and these positions require training, so Bobby is creating \n",
    "# this list to reflect the upcoming departures.\n",
    "\n",
    "# This list includes the manager's employee number, first name, last name, and their starting and ending employment \n",
    "# dates. Look at the ERD again and see where the data we need resides.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the information we need is in three tables: Departments, Managers, and Employees. \n",
    "\n",
    "# Remember, we're still using our filtered Employees table, current_emp, for this query.\n",
    "\n",
    "# Let's do this one together. At the bottom of the query editor, type the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- List of managers per department\n",
    "# SELECT  dm.dept_no,\n",
    "#         d.dept_name,\n",
    "#         dm.emp_no,\n",
    "#         ce.last_name,\n",
    "#         ce.first_name,\n",
    "#         dm.from_date,\n",
    "#         dm.to_date\n",
    "# INTO manager_info\n",
    "# FROM dept_manager AS dm\n",
    "#     INNER JOIN departments AS d\n",
    "#         ON (dm.dept_no = d.dept_no)\n",
    "#     INNER JOIN current_emp AS ce\n",
    "#         ON (dm.emp_no = ce.emp_no);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result of this query looks even more strange than the salaries. How can only five departments have active \n",
    "# managers? This is another question Bobby will need to ask his manager.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 3: Department Retirees\n",
    "\n",
    "# The final list needs only to have the departments added to the current_emp table. \n",
    "\n",
    "# We've already consolidated most of the information into one table, but let's look at the department names and \n",
    "# numbers we'll need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dept_Emp and Departments tables each have a portion of the data we'll need, so we'll need to perform two more \n",
    "# joins in the next query.\n",
    "\n",
    "# We'll use inner joins on the current_emp, departments, and dept_emp to include the list of columns we'll need to \n",
    "# present to Bobby's manager:\n",
    "\n",
    "# emp_no\n",
    "# first_name\n",
    "# last_name\n",
    "# dept_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the query editor, begin with the SELECT statement. Type the following:\n",
    "\n",
    "# SELECT ce.emp_no,\n",
    "# ce.first_name,\n",
    "# ce.last_name,\n",
    "# d.dept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we have only selected four columns from two tables, yet there are three tables in the ERD that we need. \n",
    "\n",
    "# That's because we don't need to see a column from each table in a join, but we do need the foreign and primary keys \n",
    "# to link them together. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with the INTO statement, this time naming the temporary table dept_info.\n",
    "\n",
    "# INTO dept_info\n",
    "\n",
    "# (lead with -- before executing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, start defining the aliases with FROM and the joins. In the query editor, type the following:\n",
    "\n",
    "# FROM current_emp as ce\n",
    "# INNER JOIN dept_emp AS de\n",
    "# ON (ce.emp_no = de.emp_no)\n",
    "# INNER JOIN departments AS d\n",
    "# ON (de.dept_no = d.dept_no);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After executing the code and checking the results, a few folks are are appearing twice. \n",
    "# Maybe they moved departments? \n",
    "\n",
    "# It's interesting how each list has given Bobby a question to ask his manager. \n",
    "\n",
    "# So far, Bobby would like to know the following:\n",
    "\n",
    "# What's going on with the salaries?\n",
    "# Why are there only five active managers for nine departments?\n",
    "# Why are some employees appearing twice?\n",
    "\n",
    "\n",
    "# To help Bobby find these answers, we're going to create tailored lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3.6 Create a Tailored List\n",
    "\n",
    "# Now, we have created a model of the database with an ERD, imported data, and to tie it all together, we have performed\n",
    "# many queries to help PH future-proof the company.\n",
    "\n",
    "# one manager has asked for an additional list. This list will be created using the same tools we've been working with\n",
    "# so far: queries using filters, joins, and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The department head for Sales was a little surprised at how many folks will be leaving, so has asked for an \n",
    "# additional list, containing only employees in their department. \n",
    "\n",
    "# The new list Bobby will need to make will contain everything in the retirement_info table, only tailored for the \n",
    "# Sales team.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will return only the information relevant to the Sales team. The requested list includes:\n",
    "\n",
    "# Employee numbers\n",
    "# Employee first name\n",
    "# Employee last name\n",
    "# Employee department name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --Create a query that will return only the information relevant to the Sales team.\n",
    "# SELECT re.emp_no,\n",
    "# \tre.first_name,\n",
    "# \tre.last_name,\n",
    "# \tde.dept_name\n",
    "# INTO sales_info\n",
    "# FROM retirement_info AS re\n",
    "# INNER JOIN dept_info AS de\n",
    "# \tON(re.emp_no = de.emp_no)\n",
    "# WHERE de.dept_name = 'Sales'\n",
    "\n",
    "# -- view sales_info table\n",
    "# SELECT*FROM sales_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same manager asking for a list of retiring employees has asked for a list of employees in both the Sales and \n",
    "# Development departments because, together, both managers want to try a new mentoring program for employees getting \n",
    "# ready to retire. \n",
    "\n",
    "# Instead of having a large chunk of their workforce retiring, they want to introduce a mentoring program: experienced\n",
    "# and successful employees stepping back into a part-time role instead of retiring completely. \n",
    "\n",
    "# Their new role in the company would be as a mentor to the newly hired folks. \n",
    "\n",
    "# Before they can present their idea to the CEO, they'd like to have an idea of how many people between the \n",
    "# departments they would need to pitch their idea to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another query that will return the following information for the Sales and Development teams:\n",
    "\n",
    "# Employee numbers\n",
    "# Employee first name\n",
    "# Employee last name\n",
    "# Employee department name\n",
    "\n",
    "# Hint: You'll need to use the IN condition with the WHERE clause. \n",
    "\n",
    "# The IN condition is necessary because you're creating two items in the same column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- sales and development merge\n",
    "# SELECT re.emp_no,\n",
    "# \tre.first_name,\n",
    "# \tre.last_name,\n",
    "# \tde.dept_name\n",
    "# INTO sales_and_dev_info\n",
    "# FROM retirement_info AS re\n",
    "# INNER JOIN dept_info AS de\n",
    "# \tON(re.emp_no = de.emp_no)\n",
    "# WHERE de.dept_name IN ('Sales', 'Development')\n",
    "\n",
    "# -- view sales_and_dev info\n",
    "# SELECT*FROM sales_and_dev_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTINCT ON statement \n",
    "\n",
    "# is used specifically with PostgreSQL databases. \n",
    "\n",
    "# With the DISTINCT ON statement, you can retrieve a single row defined by the ON () clause. \n",
    "# The row that is returned is specified by the ORDER BY clause.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
